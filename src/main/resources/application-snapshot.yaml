debug: true

custom:
  kafka:
    broker: kafka:29092
    topics:
      separator: ""
      names:
        activities: activities
        sensor-data: mqtt

# Native Encoding enables the kafka serialization/deserialization
spring.cloud.stream.default.producer:
  useNativeEncoding: true

spring.cloud.stream.default.consumer:
  useNativeEncoding: true

#TODO: figure out how to handle different types. maybe use connector to stream in format <key: timestamp, value: json>
#TODO:    so that the bindings can be configured for a single serializer/deserializer for all streams.

# Configure the kafka streams binder to consume messages
spring.cloud.stream.kafka.streams.binder:
  brokers: ${custom.kafka.broker}
#  configuration:
# TODO: use native encoding (is it used already?)
#    schema.registry.url: http://schema-registry:8081
#    default.key.serde: org.apache.kafka.common.serialization.Serdes$StringSerde
#    default.key.serde: org.springframework.kafka.support.serializer.JsonSerde
#    default.value.serde: io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde
#    default.value.serde: org.apache.kafka.common.serialization.Serdes$StringSerde
#    default.value.serde: com.edutec.activitydetector.AccelerometerSerde
#    default.value.serde: org.springframework.kafka.support.serializer.JsonSerde

spring.cloud.stream.bindings.input.contentType: application/json
spring.cloud.stream.bindings.input.consumer.useNativeDecoding: true
spring.cloud.stream.bindings.output.producer.useNativeEncoding: true

# Configure the bindings
spring.cloud.stream.bindings:
  sensor-data:
    destination: ${custom.kafka.topics.names.sensor-data}
  activities:
    destination: ${custom.kafka.topics.names.activities}

spring.cloud.stream.kafka.streams.bindings:
  sensor-data:
    consumer.application-id: activity-detector-sensor-data
