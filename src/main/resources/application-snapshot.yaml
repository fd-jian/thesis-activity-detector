debug: true

custom:
  kafka:
    broker: kafka:29092
    topics:
      separator: ""
      names:
        activities: activities
        sensor-data: mqtt

# Native Encoding enables the kafka serialization/deserialization
spring.cloud.stream.default.producer:
  useNativeEncoding: true

spring.cloud.stream.default.consumer:
  useNativeEncoding: true

# Connection to Kafka to produce messages (possibly not needed)
#spring.cloud.stream.kafka.binder:
#  brokers: ${custom.kafka.broker}
#  producerProperties:
#    key.serializer: org.apache.kafka.common.serialization.ByteArraySerializer
#    value.serializer: org.apache.kafka.common.serialization.ByteArraySerializer
#    value.serializer: org.springframework.kafka.support.serializer.JsonSerializer

#TODO: figure out how to handle different types. maybe use connector to stream in format <key: timestamp, value: json>
#TODO:    so that the bindings can be configured for a single serializer/deserializer for all streams.

# Configure the kafka streams binder to consume messages
spring.cloud.stream.kafka.streams.binder:
  brokers: ${custom.kafka.broker}
  configuration:
    default.key.serde: org.apache.kafka.common.serialization.Serdes$StringSerde
#    default.key.serde: org.springframework.kafka.support.serializer.JsonSerde
    default.value.serde: org.apache.kafka.common.serialization.Serdes$StringSerde
#    default.value.serde: org.springframework.kafka.support.serializer.JsonSerde

# Configure the bindings
spring.cloud.stream.bindings:
  sensor-data:
    destination: ${custom.kafka.topics.names.sensor-data}
  activities:
    destination: ${custom.kafka.topics.names.activities}

spring.cloud.stream.kafka.streams.bindings:
  sensor-data:
    consumer.application-id: activity-detector-sensor-data
